{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EfficientNetB7.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4aECrPpdBlqI"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aECrPpdBlqI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We27xp8Kxhkw",
        "outputId": "03953959-06d4-4fc6-e0d4-8824c1a62ff4"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import yaml\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "%cd /content\n",
        "%rm -rf LaPeau\n",
        "!git clone https://github.com/caohieu04/LaPeau\n",
        "%cd /content/LaPeau/yolov5-master/\n",
        "!ls\n",
        "!pip install -r requirements.txt\n",
        "!nvidia-smi\n",
        "!pip install wandb\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import imghdr\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'LaPeau'...\n",
            "remote: Enumerating objects: 2323, done.\u001b[K\n",
            "remote: Counting objects: 100% (1312/1312), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1181/1181), done.\u001b[K\n",
            "remote: Total 2323 (delta 118), reused 1304 (delta 117), pack-reused 1011\u001b[K\n",
            "Receiving objects: 100% (2323/2323), 69.50 MiB | 22.81 MiB/s, done.\n",
            "Resolving deltas: 100% (157/157), done.\n",
            "/content/LaPeau/yolov5-master\n",
            "data\t      Dockerfile  models\t    test.py\t    utils\n",
            "dataset.yaml  hubconf.py  README.md\t    train.py\t    weights\n",
            "detect.py     LICENSE\t  requirements.txt  tutorial.ipynb\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.29.22)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (5.4.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: tensorboard>=2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.9.1+cu101)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (4.41.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (1.1.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (0.0.31.post2005241907)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (3.12.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (54.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (0.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (3.3.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2->-r requirements.txt (line 11)) (1.32.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 12)) (3.7.4.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 21)) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r requirements.txt (line 11)) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r requirements.txt (line 11)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r requirements.txt (line 11)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2->-r requirements.txt (line 11)) (3.10.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2->-r requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2->-r requirements.txt (line 11)) (3.4.1)\n",
            "Sun Apr 18 03:30:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.10.26)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfRt6plGdju5",
        "outputId": "7545a477-3337-44c3-c98d-9cfb70c28ec6"
      },
      "source": [
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "%cd /content/\n",
        "!mkdir -p data\n",
        "!mkdir -p data/train\n",
        "!mkdir -p data/train/BaKhoang\n",
        "!mkdir -p data/train/VayNen\n",
        "!mkdir -p data/train/DaVayCa\n",
        "!mkdir -p data/train/Zona\n",
        "!mkdir -p data/val\n",
        "!mkdir -p data/val/BaKhoang\n",
        "!mkdir -p data/val/VayNen\n",
        "!mkdir -p data/val/DaVayCa\n",
        "!mkdir -p data/val/Zona\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CjsWlP2doky"
      },
      "source": [
        "# Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWEPRrfb0r9Z",
        "outputId": "4756ddda-3f4c-48cf-ab55-e2b0e4da3a76"
      },
      "source": [
        "img_size = 456\n",
        "y = []\n",
        "X = []\n",
        "mp = ['BaKhoang','VayNen','DaVayCa','Zona']\n",
        "def load_image( infilename ) :\n",
        "    img = Image.open( infilename )\n",
        "    img.load()\n",
        "    data = np.asarray( img, dtype=\"int32\" )\n",
        "    return data\n",
        "\n",
        "for t_or_v in ['train', 'val']:\n",
        "  label_path = '/content/LaPeau/LaPeauData/labels/' + t_or_v\n",
        "  paths = os.listdir(label_path)\n",
        "\n",
        "  for p in paths:\n",
        "    with open(os.path.join(label_path, p), encoding='utf-8-sig') as f:\n",
        "      tag = int(f.readlines()[0][0])\n",
        "      src = os.path.join('/content/LaPeau/LaPeauData/images/' + t_or_v, p.split('.')[0] + '.jpg')\n",
        "      dst = os.path.join('/content/data/' + t_or_v, mp[tag])\n",
        "      if imghdr.what(src) in ['jpeg', 'png']:\n",
        "        shutil.copy(src, dst)\n",
        "      # if not os.path.exists(dst):\n",
        "      #   shutil.move(src, dst)\n",
        "\n",
        "def add_noise(img):\n",
        "    VARIABILITY = 50\n",
        "    deviation = VARIABILITY*random.random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    return img\n",
        "# sample_count = len(os.listdir('/content/data/train'))\n",
        "batch_size = 16\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        zoom_range=0.2,\n",
        "        validation_split=0.2,\n",
        "        preprocessing_function=add_noise\n",
        "    )\n",
        "val_datagen  = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_loader = datagen.flow_from_directory(\n",
        "        '/content/data/train',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        subset='training'\n",
        "        )\n",
        "val_loader = val_datagen.flow_from_directory(\n",
        "        '/content/data/train',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        subset='validation'\n",
        "        )\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator as IGD\n",
        "generators = [IGD(rescale=1./255, validation_split=0.2, rotation_range=20),\n",
        "             IGD(rescale=1./255, validation_split=0.2, width_shift_range=0.1),\n",
        "             IGD(rescale=1./255, validation_split=0.2, height_shift_range=0.1),\n",
        "             IGD(rescale=1./255, validation_split=0.2, horizontal_flip=True),\n",
        "             IGD(rescale=1./255, validation_split=0.2, vertical_flip=True),\n",
        "             IGD(rescale=1./255, validation_split=0.2, zoom_range=0.1), \n",
        "             IGD(rescale=1./255, validation_split=0.2, preprocessing_function=add_noise) \n",
        "             ]\n",
        "\n",
        "train_x = [[] for _ in range(4)]\n",
        "train_y = [[] for _ in range(4)]\n",
        "for i in range(4):\n",
        "  MP = mp[i]\n",
        "  for path in os.listdir('/content/data/train/' + MP):\n",
        "    image_path = os.path.join('/content/data/train/' + MP, path)\n",
        "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_size, img_size))\n",
        "    input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "    # print(input_arr.shape)\n",
        "    train_x[i].append(input_arr)\n",
        "    train_y[i].append(i)\n",
        "  train_x[i] = np.array(train_x[i])\n",
        "  train_y[i] = np.array(train_y[i])\n",
        "\n",
        "# print(val_datagen.flow(train_x[0], train_y[0], batch_size=batch_size, subset='training'))\n",
        "\n",
        "IGD_boo = [[False, False, False, True, True, False, True],\n",
        "           [False, False, False, True, True, False, True],\n",
        "           [False, False, False, True, True, False, True],\n",
        "           [False, False, False, True, True, False, True] \n",
        "           ]\n",
        "# print(IGD_boo) \n",
        "batch_size = 4\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "total_cnt = 0\n",
        "for id_igd in range(len(generators)):\n",
        "  igd = generators[id_igd]\n",
        "  for id in range(4):\n",
        "    repeat = 5\n",
        "    for _ in range(repeat):\n",
        "      if not IGD_boo[id][id_igd]:\n",
        "        break\n",
        "      igd_loader = igd.flow(train_x[id], train_y[id], batch_size=1, subset='training')\n",
        "      X_te = []\n",
        "      Y_te = []\n",
        "      cnt = 0\n",
        "      while cnt < len(train_x[id]):\n",
        "        batch = igd_loader.next()\n",
        "        cnt += batch[1].shape[0]\n",
        "        total_cnt += batch[1].shape[0]\n",
        "        X_te.append(batch[0])\n",
        "        Y_te.append(batch[1])\n",
        "      \n",
        "      print(len(X))\n",
        "      if (len(X) == 0):\n",
        "        X = np.array(X_te)\n",
        "        Y = np.array(Y_te)\n",
        "      else:\n",
        "        X = np.concatenate((X, X_te))\n",
        "        Y = np.concatenate((Y, Y_te))\n",
        "print(total_cnt)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "# while (len(X)) < 40 // batch_size:\n",
        "#   batch = train_loader.next() \n",
        "#   X.append(batch[0])\n",
        "#   Y.append(batch[1])\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "print(X.shape, Y.shape)\n",
        "# X = X.reshape(X.shape[0] * X.shape[1], X.shape[2], X.shape[3], X.shape[4])\n",
        "# Y = Y.reshape(Y.shape[0] * Y.shape[1])\n",
        "# print(X.shape, Y.shape)\n",
        "batch_size = 16\n",
        "\n",
        "val_loader = val_datagen.flow_from_directory(\n",
        "        '/content/data/train',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        subset='validation'\n",
        "        )\n",
        "f\n",
        "  \n",
        "\n",
        "# X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "# print(X)\n",
        "# print(Y)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 229 images belonging to 4 classes.\n",
            "Found 57 images belonging to 4 classes.\n",
            "0\n",
            "65\n",
            "130\n",
            "195\n",
            "260\n",
            "325\n",
            "400\n",
            "475\n",
            "550\n",
            "625\n",
            "700\n",
            "786\n",
            "872\n",
            "958\n",
            "1044\n",
            "1130\n",
            "1190\n",
            "1250\n",
            "1310\n",
            "1370\n",
            "1430\n",
            "1495\n",
            "1560\n",
            "1625\n",
            "1690\n",
            "1755\n",
            "1830\n",
            "1905\n",
            "1980\n",
            "2055\n",
            "2130\n",
            "2216\n",
            "2302\n",
            "2388\n",
            "2474\n",
            "2560\n",
            "2620\n",
            "2680\n",
            "2740\n",
            "2800\n",
            "2860\n",
            "2925\n",
            "2990\n",
            "3055\n",
            "3120\n",
            "3185\n",
            "3260\n",
            "3335\n",
            "3410\n",
            "3485\n",
            "3560\n",
            "3646\n",
            "3732\n",
            "3818\n",
            "3904\n",
            "3990\n",
            "4050\n",
            "4110\n",
            "4170\n",
            "4230\n",
            "4290\n",
            "(4290, 1, 456, 456, 3) (4290, 1)\n",
            "Found 57 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/LaPeau/LaPeauData/labels/val/i156.txt' mode='r' encoding='utf-8-sig'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3MwKSPAmWFX",
        "outputId": "351dcec2-c657-4181-dc46-71ab792218e3"
      },
      "source": [
        "from PIL import Image\n",
        "%cd /content/\n",
        "!rm -r aguData\n",
        "!mkdir -p aguData\n",
        "!mkdir -p aguData/BaKhoang/\n",
        "!mkdir -p aguData/VayNen\n",
        "!mkdir -p aguData/DaVayCa\n",
        "!mkdir -p aguData/Zona\n",
        "mp = ['BaKhoang','VayNen','DaVayCa','Zona']\n",
        "%cd aguData\n",
        "\n",
        "y = Y[0][:]\n",
        "for id in range(1, len(Y)):\n",
        "  # print(y.shape, Y[id].shape)\n",
        "  y = np.concatenate((y, Y[id]))\n",
        "print(y.shape)\n",
        "cur_cnt = 0\n",
        "for id in range(len(X)):\n",
        "  for batch in range(X[id].shape[0]):\n",
        "    im = Image.fromarray((X[id][batch] * 255).astype(np.uint8))\n",
        "    im.save(f'{mp[y[cur_cnt]]}/image_{id}_{batch}.jpeg')\n",
        "    cur_cnt += 1\n",
        "  # print(x.shape, X[id].shape)\n",
        "  # x = np.concatenate((x, X[id]))\n",
        "print(cur_cnt)\n",
        "  \n",
        "\n",
        "%cd ..\n",
        "# X, Y = x, y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/aguData\n",
            "(4290,)\n",
            "4290\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avgB8nxp21Xn"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q0Mp8odx8-1",
        "outputId": "9dec40a0-7ceb-4187-f139-2407c9954da9"
      },
      "source": [
        "t1 = len(os.listdir('/content/aguData/BaKhoang'))\n",
        "t2 = len(os.listdir('/content/aguData/DaVayCa'))\n",
        "t3 = len(os.listdir('/content/aguData/VayNen'))\n",
        "t4 = len(os.listdir('/content/aguData/Zona'))\n",
        "print(t1 + t2 + t3 + t4)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0yRBStBTFgF",
        "outputId": "3e604a01-c0e5-4316-e1d6-457bfdf4ff95"
      },
      "source": [
        "batch_size = 2\n",
        "\n",
        "train_loader = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "        '/content/aguData/',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=\"categorical\",\n",
        "        subset='training'\n",
        "        )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4290 images belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHRcsHyy-SAt"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9EUJczyBpWz"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy3h0vdBxmJx",
        "outputId": "26e51e30-2b3e-4709-8207-72196a95d78f"
      },
      "source": [
        "IMG_SIZE = img_size\n",
        "IMG_SHAPE = shape = (img_size, img_size, 3)\n",
        "NUM_CLASSES = 4\n",
        "base_model = tf.keras.applications.EfficientNetB5(input_shape=IMG_SHAPE, include_top=False, drop_connect_rate=0.4, weights='imagenet')\n",
        "base_model.trainable = True\n",
        "batch_size = 4\n",
        "inputs = tf.keras.Input(IMG_SHAPE)\n",
        "x = base_model(inputs, training=True)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "#x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "#x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "#x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "from tensorflow.keras import *\n",
        "EPOCHS = 300\n",
        "lr = 0.0001\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 1:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.05)\n",
        "#tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "def lr_finder(num_epochs, base_lr=1e-6, max_lr=0.01):\n",
        "  cur_lr = base_lr\n",
        "  lrs = []\n",
        "  accs = []\n",
        "  best_acc = 0.0\n",
        "  while cur_lr < max_lr:\n",
        "    print(f'Training learning rate {cur_lr}')\n",
        "    callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)]\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy', f1_score])\n",
        "    history = model.fit(train_loader, epochs=EPOCHS, callbacks=[callback], \n",
        "              validation_data = val_loader)\n",
        "    acc = history.history['accuracy'][-1]\n",
        "    if  acc > best_acc:\n",
        "      best_acc = acc\n",
        "      best_lr = lr\n",
        "    lrs.append(cur_lr)\n",
        "    accs.append(acc)\n",
        "    cur_lr *= 3\n",
        "  print(lrs, accs)\n",
        "  sns.lineplot(x=lrs, y=accs)\n",
        "  return best_lr, best_acc\n",
        "\n",
        "# lr, test_acc = lr_finder(2)\n",
        "\n",
        "\n",
        "# lr = 0.00007\n",
        "# warmup_epoch = int(EPOCHS / 20)\n",
        "# epochs = EPOCHS\n",
        "# callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)]\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "#           loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#           metrics=['accuracy', f1_score])\n",
        "# history = model.fit(train_loader, epochs=EPOCHS, callbacks=[callback], \n",
        "#           validation_data = val_loader)\n",
        "\n",
        "def unfreeze_model(model):\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    # mcp_save = tf.keras.callbacks.ModelCheckpoint('best_val2.hdf5', save_best_only=True, monitor='val_f1_score', mode='min')\n",
        "    # optimizer = tf.keras.optimizers.Adam(learning_rate=7e-5)\n",
        "    # model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", f1_score])\n",
        "\n",
        "unfreeze_model(model)\n",
        "epochs = 10  \n",
        "# param {type: \"slider\", min:8, max:50}\n",
        "# callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40)]\n",
        "# hist = model.fit(X, Y, epochs=epochs, validation_data=val_loader, callbacks=[callback])\n",
        "\n",
        "!pip install tensorflow_addons\n",
        "import sklearn\n",
        "import tensorflow_addons as tfa\n",
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('best_val.hdf5', save_best_only=True, monitor='val_f1_score', mode='min')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_score])\n",
        "\n",
        "X_te = X[:]\n",
        "Y_te = Y[:]\n",
        "Y_te = tf.keras.utils.to_categorical(Y_te, num_classes=4)\n",
        "print(Y_te.shape)\n",
        "epochs=7\n",
        "history = model.fit(train_loader, epochs=epochs,  validation_data=val_loader, callbacks=[mcp_save])\n",
        "# history = model.fit(X_te, Y_te, epochs=epochs,  validation_data=val_loader, callbacks=[mcp_save], batch_size=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "(4290, 4)\n",
            "Epoch 1/7\n",
            "1373/2145 [==================>...........] - ETA: 2:23 - loss: 1.7362 - accuracy: 0.3016 - f1_score: 0.2288"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dRfqDA_jS0X"
      },
      "source": [
        "train_loader = datagen.flow_from_directory(\n",
        "        'data/train',\n",
        "        target_size=(img_size, img_size),\n",
        "        batch_size=4,\n",
        "        class_mode=\"categorical\",\n",
        "        subset='training'\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eCDwgXUE-sV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC82I09TFAcn"
      },
      "source": [
        "# After trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ9mQytZDhPR"
      },
      "source": [
        "mcp_save = tf.keras.callbacks.ModelCheckpoint('best_val.hdf5', save_best_only=True, monitor='val_f1_score', mode='min')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=7e-5)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_score])\n",
        "history = model.fit(X_te, Y_te, epochs=10, validation_data=val_loader, callbacks=[mcp_save], batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQnkyUgEP63G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEg_u5EJ368Q"
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "history = hist\n",
        "plt.plot(history.history['f1_score'])\n",
        "print('Average validation F1 Score: ', np.mean(history.history['val_f1_score'][61:]))\n",
        "print('Average training F1 Score: ', np.mean(history.history['f1_score'][61:]))\n",
        "plt.plot(history.history['val_f1_score'])\n",
        "plt.title('model f1_score')\n",
        "plt.ylabel('f1_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qETzQASA38m3"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1gUwhgjCrN8"
      },
      "source": [
        "# num_epochs = 2\n",
        "# cur_lr = 0.1\n",
        "# warmup_epoch = int(num_epochs / 10)\n",
        "# epochs = num_epochs \n",
        "# warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=cur_lr,\n",
        "#                                     total_steps=int(epochs * sample_count / batch_size),\n",
        "#                                     warmup_learning_rate=0.0,\n",
        "#                                     warmup_steps=int(warmup_epoch * sample_count / batch_size),\n",
        "#                                     hold_base_rate_steps=0)\n",
        "# callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15), warm_up_lr]\n",
        "# model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=lr),\n",
        "#           loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#           metrics=['accuracy'])\n",
        "# history = model.fit(train_loader, epochs=num_epochs, callbacks=[callback], validation_data=val_loader)\n",
        "# acc = history.history['accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8v3fz3_C0Ov"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5KE8a7X9oyU"
      },
      "source": [
        "print(val_loader.filenames)\n",
        "\n",
        "test_ = []\n",
        "for fn in val_loader.filenames:\n",
        "  image_path = os.path.join('/content/data/train', fn)\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_size, img_size))\n",
        "  input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "  test_.append(input_arr)\n",
        "test_ = np.array(test_)\n",
        "print(test_.shape)\n",
        "# print(test_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzzaf_75fMT7"
      },
      "source": [
        "# from google.colab import files\n",
        "# model.save('my_model.h5')\n",
        "files.download('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18bca8xIaUI0"
      },
      "source": [
        "# # print(vars(val_loader))\n",
        "# def get_npimgs(loader):\n",
        "#   data_list = []\n",
        "#   batch_index = 0\n",
        "\n",
        "\n",
        "#   while batch_index <= loader.batch_index:\n",
        "#       data = loader.next()\n",
        "#       data_list.append(data[0])\n",
        "#       print(len(data), data[0].shape)\n",
        "#       batch_index = batch_index + 1\n",
        "\n",
        "#   # now, data_array is the numeric data of whole images\n",
        "#   data_array = np.array(data_list)\n",
        "#   print(data_array.shape)\n",
        "#   return data_array\n",
        "\n",
        "# y_preded = get_npimgs(val_loader)\n",
        "# y_preded = np.concatenate(y_preded)\n",
        "\n",
        "y_pred = model.predict(test_)\n",
        "y_true = val_loader.classes\n",
        "# print(y_preded.shape)\n",
        "# y_pred = model.predict(tf.convert_to_tensor(y_preded)[1])\n",
        "# print(y_pred)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "f1_ = f1_score(tf.keras.utils.to_categorical(y_pred, num_classes=4), tf.keras.utils.to_categorical(y_true, num_classes=4))\n",
        "if f1_ < 0.9:\n",
        "  continue\n",
        "\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "print(y_true)\n",
        "print(y_pred)\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# print(confusion_matrix(y_true, y_pred, ))\n",
        "cmtx = np.round(confusion_matrix(y_true, y_pred, labels=[0, 1, 2, 3]), decimals=2)\n",
        "print(cmtx)\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "\n",
        "print(f'f1 score: {f1_}')\n",
        "figure(figsize=(12, 12), dpi=80)\n",
        "\n",
        "# sns.heatmap(cmtx, annot=True)\n",
        "sum = cmtx.sum(axis=1)\n",
        "cmtx = cmtx / sum[:, ...]\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cmtx, annot=True, fmt='g', ax=ax)\n",
        "ax.xaxis.set_ticklabels(mp)\n",
        "ax.yaxis.set_ticklabels(mp)\n",
        "# print(cmtx)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "# (tn, fp, fn, tp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-1-SS1ElGra"
      },
      "source": [
        "plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
        "plt.axis('off')\n",
        "\n",
        "for i in range(50):\n",
        "    plt.subplot(5,10,i+1)    # the number of images in the grid is 5*5 (25)\n",
        "    plt.imshow(X[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKwC83XQaclR"
      },
      "source": [
        "# IMG_SHAPE = shape=(300, 300, 3)\n",
        "# inputs = tf.keras.Input(IMG_SHAPE)\n",
        "# x = tf.keras.layers.Conv2D(128, 3, padding='same')(inputs)\n",
        "# x = tf.keras.layers.Conv2D(128, 5, padding='same')(x)\n",
        "# x = tf.keras.layers.Conv2D(128, 7, padding='same')(x)\n",
        "# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# # x = tf.keras.layers.Dropout(0.5)(x)\n",
        "# # x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "# x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "# outputs = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
        "# model = tf.keras.Model(inputs, outputs)\n",
        "# EPOCHS = 20\n",
        "# lr = 0.0001\n",
        "# warmup_epoch = int(EPOCHS / 20)\n",
        "# epochs = EPOCHS\n",
        "# warm_up_lr = WarmUpCosineDecayScheduler(learning_rate_base=lr,\n",
        "#                                         total_steps=int(epochs * sample_count / batch_size),\n",
        "#                                         warmup_learning_rate=0.0,\n",
        "#                                         warmup_steps=int(warmup_epoch * sample_count / batch_size),\n",
        "#                                         hold_base_rate_steps=0)\n",
        "# # te_lr = lr\n",
        "# # lr_np = []\n",
        "# print(lr)\n",
        "# # for epoch in range(EPOCHS):\n",
        "# #   lr_np.append(scheduler(epoch, te_lr))\n",
        "# #   te_lr = scheduler(epoch, te_lr)\n",
        "# # sns.set_style(\"darkgrid\")\n",
        "# # plt.plot(np.array(lr_np))\n",
        "# # plt.show()\n",
        "\n",
        "# callback = [tf.keras.callbacks.EarlyStopping(monitor='loss', patience=40), warm_up_lr]\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr),\n",
        "#           loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "#           metrics=['accuracy'])\n",
        "# history = model.fit(train_loader, epochs=EPOCHS, callbacks=[callback], validation_data=val_loader)\n",
        "# te_lr = lr\n",
        "# lr_np = []\n",
        "print(lr)\n",
        "# for epoch in range(EPOCHS):\n",
        "#   lr_np.append(scheduler(epoch, te_lr))\n",
        "#   te_lr = scheduler(epoch, te_lr)\n",
        "# sns.set_style(\"darkgrid\")\n",
        "# plt.plot(np.array(lr_np))\n",
        "# plt.show()\n",
        "\n",
        "# val_loader = val_datagen.flow_from_directory(\n",
        "#         'data/val',\n",
        "#         target_size=(300, 300),\n",
        "#         batch_size=batch_size,\n",
        "#         class_mode=\"categorical\",)\n",
        "\n",
        "\n",
        "# train_loader = tf.keras.preprocessing.image.(\n",
        "#     '/content/data/train/',\n",
        "#     labels=\"inferred\",\n",
        "#     label_mode=\"int\",\n",
        "#     class_names=None,\n",
        "#     color_mode=\"rgb\",\n",
        "#     batch_size=4,\n",
        "#     image_size=(300, 300),\n",
        "#     shuffle=True,\n",
        "#     seed=69,\n",
        "#     interpolation=\"bilinear\",\n",
        "# )\n",
        "# val_loader = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#     '/content/data/val/',\n",
        "#     labels=\"inferred\",\n",
        "#     label_mode=\"int\",\n",
        "#     class_names=None,\n",
        "#     color_mode=\"rgb\",\n",
        "#     batch_size=4,\n",
        "#     image_size=(300, 300),\n",
        "#     shuffle=True,\n",
        "#     seed=69,\n",
        "#     interpolation=\"bilinear\",\n",
        "# )\n",
        "# train_x = [[] for _ in range(4)]\n",
        "# train_y = [[] for _ in range(4)]\n",
        "# for i in range(4):\n",
        "#   MP = mp[i]\n",
        "#   for path in os.listdir('/content/data/train/' + MP):\n",
        "#     image_path = os.path.join('/content/data/train/' + MP, path)\n",
        "#     image = tf.keras.preprocessing.image.load_img(image_path)\n",
        "#     input_arr = keras.preprocessing.image.img_to_array(image)\n",
        "#     # print(input_arr.shape)\n",
        "#     train_x[i].append(input_arr)\n",
        "#     train_y[i].append(i)\n",
        "# print(val_datagen.flow(train_x[0], train_y[0], batch_size=batch_size, subset='training'))\n",
        "# mcp_save = tf.keras.callbacks.ModelCheckpoint('best_val.hdf5', save_best_only=True, monitor='val_f1_score', mode='min')\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=7e-5)\n",
        "# model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1_score])\n",
        "# history = model.fit(train_loader, epochs=10, validation_data=val_loader, callbacks=[mcp_save])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI8jhSrvml8h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}